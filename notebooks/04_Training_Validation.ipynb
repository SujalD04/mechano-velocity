{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üè• Mechano-Velocity: Notebook 04 - Training & Validation\n",
                "\n",
                "**Clinical Scoring and Model Validation**\n",
                "\n",
                "This notebook:\n",
                "1. Generates clinical risk scores (MTS, Metastatic Risk, Immune Exclusion)\n",
                "2. Validates model predictions against histology\n",
                "3. Runs ablation studies\n",
                "4. Stores results in database\n",
                "5. (Optional) GNN training for advanced physics-informed learning\n",
                "\n",
                "---\n",
                "\n",
                "## Clinical Metrics\n",
                "\n",
                "**Mechano-Therapeutic Score (MTS):**\n",
                "$$MTS = \\frac{\\text{T-cell Infiltration Flux}}{\\text{Cancer Metastasis Flux}}$$\n",
                "\n",
                "| MTS Range | Classification | Recommendation |\n",
                "|-----------|---------------|----------------|\n",
                "| > 2.0 | Hot / Leaky | Standard Immunotherapy |\n",
                "| 0.5 - 2.0 | Intermediate | Consider Combination |\n",
                "| < 0.5 | Cold / Trapped | Anti-fibrotic + Immunotherapy |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check environment\n",
                "import sys\n",
                "IN_COLAB = 'google.colab' in sys.modules\n",
                "\n",
                "if IN_COLAB:\n",
                "    %cd /content/mechano-velocity"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Core imports\n",
                "import scanpy as sc\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import json\n",
                "from datetime import datetime\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "sc.settings.verbosity = 2\n",
                "sc.settings.set_figure_params(dpi=100, frameon=False, figsize=(8, 8))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import project modules\n",
                "from pathlib import Path\n",
                "sys.path.insert(0, '.')\n",
                "\n",
                "from mechano_velocity import (\n",
                "    Config, ClinicalScorer, Visualizer, DatabaseManager\n",
                ")\n",
                "\n",
                "PROJECT_ROOT = Path('.').resolve()\n",
                "print(f\"Project: {PROJECT_ROOT}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load configuration\n",
                "config = Config()\n",
                "config.output_dir = PROJECT_ROOT / \"output\"\n",
                "\n",
                "# Load velocity-corrected data\n",
                "adata_path = config.output_dir / 'velocity_corrected_adata.h5ad'\n",
                "\n",
                "if adata_path.exists():\n",
                "    adata = sc.read_h5ad(adata_path)\n",
                "    print(f\"Loaded: {adata.shape}\")\n",
                "else:\n",
                "    raise FileNotFoundError(\"Please run 03_Graph_Simulation.ipynb first.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify required fields\n",
                "required = ['resistance', 'velocity_magnitude']\n",
                "missing = [r for r in required if r not in adata.obs.columns]\n",
                "\n",
                "if missing:\n",
                "    raise ValueError(f\"Missing required fields: {missing}\")\n",
                "\n",
                "print(\"\\n‚úÖ All required fields present\")\n",
                "print(f\"  obsm keys: {list(adata.obsm.keys())}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Initialize Database"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize database for storing results\n",
                "db = DatabaseManager(config=config)\n",
                "\n",
                "print(f\"Database initialized: {db.db_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Start analysis run\n",
                "run_id = db.start_analysis_run(\n",
                "    sample_id=config.dataset_name,\n",
                "    n_spots=adata.n_obs,\n",
                "    n_genes=adata.n_vars,\n",
                "    config_dict=config.to_dict(),\n",
                "    notes=\"Full pipeline analysis with clinical scoring\"\n",
                ")\n",
                "\n",
                "print(f\"\\nüìä Analysis Run ID: {run_id}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Generate Clinical Report"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize clinical scorer\n",
                "scorer = ClinicalScorer(config)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate clinical report\n",
                "report = scorer.generate_report(\n",
                "    adata,\n",
                "    sample_id=config.dataset_name,\n",
                "    tumor_cluster=None,  # Auto-detect from markers\n",
                "    tcell_threshold=0.3\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# View the clinical report\n",
                "print(report.to_text())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save report to files\n",
                "scorer.save_report(config.output_dir / 'clinical_report.txt', format='txt')\n",
                "scorer.save_report(config.output_dir / 'clinical_report.json', format='json')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Store report in database\n",
                "report_id = db.save_clinical_report(run_id, report.to_dict())\n",
                "print(f\"Report saved to database with ID: {report_id}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Visualize Clinical Findings"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize visualizer\n",
                "viz = Visualizer(config)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell type spatial plot\n",
                "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
                "\n",
                "# Tumor regions\n",
                "if 'is_tumor' in adata.obs.columns:\n",
                "    sc.pl.spatial(adata, color='is_tumor', ax=axes[0], show=False,\n",
                "                  title='Tumor Regions', palette={True: 'red', False: 'lightgray'})\n",
                "else:\n",
                "    axes[0].text(0.5, 0.5, 'No tumor markers', ha='center', va='center')\n",
                "    axes[0].set_title('Tumor Regions')\n",
                "\n",
                "# T-cell regions\n",
                "if 'is_tcell' in adata.obs.columns:\n",
                "    sc.pl.spatial(adata, color='is_tcell', ax=axes[1], show=False,\n",
                "                  title='T-cell Regions', palette={True: 'blue', False: 'lightgray'})\n",
                "else:\n",
                "    axes[1].text(0.5, 0.5, 'No T-cell markers', ha='center', va='center')\n",
                "    axes[1].set_title('T-cell Regions')\n",
                "\n",
                "# Boundary regions\n",
                "if 'is_boundary' in adata.obs.columns:\n",
                "    sc.pl.spatial(adata, color='is_boundary', ax=axes[2], show=False,\n",
                "                  title='Tumor Boundary', palette={True: 'orange', False: 'lightgray'})\n",
                "else:\n",
                "    axes[2].text(0.5, 0.5, 'No boundary defined', ha='center', va='center')\n",
                "    axes[2].set_title('Tumor Boundary')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(config.output_dir / 'cell_type_regions.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clinical scores visualization\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
                "\n",
                "# Score bars\n",
                "scores = [\n",
                "    ('Metastatic Risk', report.metastatic_risk_score),\n",
                "    ('Immune Exclusion', report.immune_exclusion_score),\n",
                "    ('MTS', report.mechano_therapeutic_score)\n",
                "]\n",
                "\n",
                "for i, (name, score) in enumerate(scores):\n",
                "    color = 'steelblue' if i < 2 else ('green' if score > 2 else 'red' if score < 0.5 else 'orange')\n",
                "    axes[i].barh([0], [score], color=color, height=0.5)\n",
                "    axes[i].set_xlim(0, max(score * 1.5, 1))\n",
                "    axes[i].set_xlabel(name, fontsize=12)\n",
                "    axes[i].set_yticks([])\n",
                "    axes[i].set_title(f'{name}: {score:.4f}', fontsize=14)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(config.output_dir / 'clinical_scores.png', dpi=150)\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\nüè• CLINICAL CLASSIFICATION: {report.risk_category}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Validation Studies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Validation 1: Resistance-Velocity Correlation\n",
                "# Hypothesis: Higher resistance should correlate with lower velocity\n",
                "\n",
                "from scipy import stats\n",
                "\n",
                "resistance = adata.obs['resistance'].values\n",
                "velocity = adata.obs['velocity_magnitude'].values\n",
                "\n",
                "correlation, p_value = stats.pearsonr(resistance, velocity)\n",
                "\n",
                "print(\"\\nüìä VALIDATION 1: Resistance-Velocity Correlation\")\n",
                "print(f\"  Pearson r: {correlation:.4f}\")\n",
                "print(f\"  P-value: {p_value:.2e}\")\n",
                "print(f\"  Expected: Negative correlation (high R ‚Üí low V)\")\n",
                "print(f\"  Result: {'‚úÖ PASS' if correlation < 0 else '‚ö†Ô∏è CHECK'}\")\n",
                "\n",
                "# Log to database\n",
                "db.add_validation_log(\n",
                "    run_id=run_id,\n",
                "    validation_type='resistance_velocity_correlation',\n",
                "    expected='r < 0',\n",
                "    actual=f'r = {correlation:.4f}',\n",
                "    passed=correlation < 0,\n",
                "    notes=f'p-value: {p_value:.2e}'\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize correlation\n",
                "fig, ax = plt.subplots(figsize=(8, 6))\n",
                "\n",
                "ax.scatter(resistance, velocity, alpha=0.3, s=10, c='steelblue')\n",
                "\n",
                "# Fit line\n",
                "z = np.polyfit(resistance, velocity, 1)\n",
                "p = np.poly1d(z)\n",
                "x_line = np.linspace(resistance.min(), resistance.max(), 100)\n",
                "ax.plot(x_line, p(x_line), 'r--', linewidth=2, label=f'r = {correlation:.3f}')\n",
                "\n",
                "ax.set_xlabel('Resistance', fontsize=12)\n",
                "ax.set_ylabel('Velocity Magnitude', fontsize=12)\n",
                "ax.set_title('Resistance vs Velocity Correlation', fontsize=14)\n",
                "ax.legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(config.output_dir / 'validation_correlation.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Validation 2: Wall vs Non-Wall Velocity Comparison\n",
                "# Hypothesis: Spots in \"wall\" regions should have lower velocity\n",
                "\n",
                "wall_mask = adata.obs['resistance_category'] == 'wall'\n",
                "fluid_mask = adata.obs['resistance_category'] == 'fluid'\n",
                "\n",
                "if wall_mask.sum() > 0 and fluid_mask.sum() > 0:\n",
                "    wall_velocity = velocity[wall_mask]\n",
                "    fluid_velocity = velocity[fluid_mask]\n",
                "    \n",
                "    # T-test\n",
                "    t_stat, t_pvalue = stats.ttest_ind(wall_velocity, fluid_velocity)\n",
                "    \n",
                "    print(\"\\nüìä VALIDATION 2: Wall vs Fluid Velocity\")\n",
                "    print(f\"  Wall mean velocity: {wall_velocity.mean():.4f}\")\n",
                "    print(f\"  Fluid mean velocity: {fluid_velocity.mean():.4f}\")\n",
                "    print(f\"  T-statistic: {t_stat:.4f}\")\n",
                "    print(f\"  P-value: {t_pvalue:.2e}\")\n",
                "    print(f\"  Expected: Wall < Fluid\")\n",
                "    print(f\"  Result: {'‚úÖ PASS' if wall_velocity.mean() < fluid_velocity.mean() else '‚ö†Ô∏è CHECK'}\")\n",
                "    \n",
                "    # Log to database\n",
                "    db.add_validation_log(\n",
                "        run_id=run_id,\n",
                "        validation_type='wall_vs_fluid_velocity',\n",
                "        expected='wall < fluid',\n",
                "        actual=f'wall={wall_velocity.mean():.4f}, fluid={fluid_velocity.mean():.4f}',\n",
                "        passed=wall_velocity.mean() < fluid_velocity.mean(),\n",
                "        notes=f'p-value: {t_pvalue:.2e}'\n",
                "    )\n",
                "else:\n",
                "    print(\"\\n‚ö†Ô∏è Not enough spots in wall/fluid categories for comparison\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize wall vs fluid\n",
                "fig, ax = plt.subplots(figsize=(8, 6))\n",
                "\n",
                "categories = ['wall', 'normal', 'fluid']\n",
                "velocities = []\n",
                "for cat in categories:\n",
                "    mask = adata.obs['resistance_category'] == cat\n",
                "    if mask.sum() > 0:\n",
                "        velocities.append(velocity[mask])\n",
                "    else:\n",
                "        velocities.append(np.array([0]))\n",
                "\n",
                "ax.boxplot(velocities, labels=categories)\n",
                "ax.set_xlabel('Resistance Category', fontsize=12)\n",
                "ax.set_ylabel('Velocity Magnitude', fontsize=12)\n",
                "ax.set_title('Velocity by Resistance Category', fontsize=14)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(config.output_dir / 'validation_boxplot.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Ablation Study"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test: What if we ignore resistance entirely?\n",
                "# Compare corrected vs uncorrected velocity distributions\n",
                "\n",
                "print(\"\\nüìä ABLATION: Effect of Resistance Correction\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "# With correction (current)\n",
                "corrected_mag = adata.obs['velocity_magnitude'].values\n",
                "\n",
                "# Calculate what uncorrected would look like\n",
                "# (uniform velocity based on spatial distance only)\n",
                "from sklearn.neighbors import NearestNeighbors\n",
                "coords = adata.obsm['spatial']\n",
                "nbrs = NearestNeighbors(n_neighbors=7)\n",
                "nbrs.fit(coords)\n",
                "distances, indices = nbrs.kneighbors(coords)\n",
                "\n",
                "# Uncorrected: average distance to neighbors (uniform)\n",
                "uncorrected_mag = distances[:, 1:].mean(axis=1)  # Exclude self\n",
                "uncorrected_mag = uncorrected_mag / uncorrected_mag.max()  # Normalize\n",
                "\n",
                "print(f\"  Corrected mean: {corrected_mag.mean():.4f}\")\n",
                "print(f\"  Uncorrected mean: {uncorrected_mag.mean():.4f}\")\n",
                "print(f\"  Variance reduction: {1 - corrected_mag.var()/uncorrected_mag.var():.2%}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize ablation\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Distribution comparison\n",
                "axes[0].hist(uncorrected_mag, bins=50, alpha=0.5, label='Uncorrected', color='blue')\n",
                "axes[0].hist(corrected_mag, bins=50, alpha=0.5, label='Corrected', color='red')\n",
                "axes[0].set_xlabel('Velocity Magnitude')\n",
                "axes[0].set_ylabel('Frequency')\n",
                "axes[0].set_title('Velocity Distribution: Corrected vs Uncorrected')\n",
                "axes[0].legend()\n",
                "\n",
                "# Scatter\n",
                "axes[1].scatter(uncorrected_mag, corrected_mag, alpha=0.3, s=10)\n",
                "axes[1].plot([0, 1], [0, 1], 'r--', label='y = x')\n",
                "axes[1].set_xlabel('Uncorrected Velocity')\n",
                "axes[1].set_ylabel('Corrected Velocity')\n",
                "axes[1].set_title('Effect of Resistance Correction')\n",
                "axes[1].legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(config.output_dir / 'ablation_study.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Store Spot-Level Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save detailed spot data to database\n",
                "n_spots = db.save_spot_data(run_id, adata)\n",
                "print(f\"Saved {n_spots} spots to database\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Mark analysis as complete\n",
                "db.complete_analysis_run(run_id, status='completed')\n",
                "print(f\"\\n‚úÖ Analysis run {run_id} marked as complete\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Query Database"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# View all analysis runs\n",
                "runs = db.get_analysis_runs(limit=10)\n",
                "print(\"\\nüìã Recent Analysis Runs:\")\n",
                "for run in runs:\n",
                "    print(f\"  Run {run['id']}: {run['sample_id']} ({run['status']}) - {run['run_timestamp']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# View clinical reports\n",
                "reports = db.get_clinical_reports(run_id=run_id)\n",
                "if reports:\n",
                "    print(\"\\nüè• Clinical Reports:\")\n",
                "    for r in reports:\n",
                "        print(f\"  Report {r['id']}:\")\n",
                "        print(f\"    MTS: {r['mts_score']:.4f}\")\n",
                "        print(f\"    Risk: {r['risk_category']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Export spot data to CSV for external analysis\n",
                "csv_path = config.output_dir / f'run_{run_id}_spots.csv'\n",
                "db.export_to_csv(run_id, csv_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. (Optional) GNN Training\n",
                "\n",
                "For more advanced physics-informed learning, you can train a GNN.\n",
                "This section is optional and requires PyTorch."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check for PyTorch\n",
                "try:\n",
                "    import torch\n",
                "    import torch.nn as nn\n",
                "    import torch.nn.functional as F\n",
                "    HAS_TORCH = True\n",
                "    print(f\"PyTorch version: {torch.__version__}\")\n",
                "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "except ImportError:\n",
                "    HAS_TORCH = False\n",
                "    print(\"PyTorch not available - skipping GNN training\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if HAS_TORCH:\n",
                "    try:\n",
                "        from torch_geometric.nn import GCNConv, SAGEConv\n",
                "        from torch_geometric.data import Data\n",
                "        HAS_PYG = True\n",
                "        print(\"PyTorch Geometric available\")\n",
                "    except ImportError:\n",
                "        HAS_PYG = False\n",
                "        print(\"PyTorch Geometric not available\")\n",
                "else:\n",
                "    HAS_PYG = False"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if HAS_TORCH and HAS_PYG:\n",
                "    # Load PyG data\n",
                "    pyg_path = config.output_dir / 'spatial_graph.pt'\n",
                "    \n",
                "    if pyg_path.exists():\n",
                "        data = torch.load(pyg_path)\n",
                "        print(f\"Loaded PyG data: {data}\")\n",
                "        \n",
                "        # Simple GNN for resistance prediction\n",
                "        class ResistanceGNN(nn.Module):\n",
                "            def __init__(self, in_channels, hidden_channels):\n",
                "                super().__init__()\n",
                "                self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
                "                self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
                "                self.linear = nn.Linear(hidden_channels, 1)\n",
                "                \n",
                "            def forward(self, x, edge_index):\n",
                "                x = F.relu(self.conv1(x, edge_index))\n",
                "                x = F.dropout(x, p=0.2, training=self.training)\n",
                "                x = F.relu(self.conv2(x, edge_index))\n",
                "                x = torch.sigmoid(self.linear(x))\n",
                "                return x.squeeze()\n",
                "        \n",
                "        print(\"\\nGNN model defined. Ready for training.\")\n",
                "        print(\"Note: Full training requires labeled data/ground truth.\")\n",
                "    else:\n",
                "        print(f\"PyG data not found at {pyg_path}\")\n",
                "        print(\"Run notebook 03 to generate it.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Final Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Final summary\n",
                "print(\"=\"*60)\n",
                "print(\"MECHANO-VELOCITY ANALYSIS COMPLETE\")\n",
                "print(\"=\"*60)\n",
                "print(f\"\\nSample: {config.dataset_name}\")\n",
                "print(f\"Spots analyzed: {adata.n_obs}\")\n",
                "print(f\"Analysis Run ID: {run_id}\")\n",
                "print(f\"\\nCLINICAL RESULTS:\")\n",
                "print(f\"  Metastatic Risk Score: {report.metastatic_risk_score:.4f}\")\n",
                "print(f\"  Immune Exclusion Score: {report.immune_exclusion_score:.4f}\")\n",
                "print(f\"  Mechano-Therapeutic Score: {report.mechano_therapeutic_score:.4f}\")\n",
                "print(f\"\\n  Classification: {report.risk_category}\")\n",
                "print(f\"\\n  Recommendation: {report.therapeutic_recommendation}\")\n",
                "print(f\"\\nOutput files saved to: {config.output_dir}\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "‚úÖ Generated clinical risk scores (MTS, Metastatic Risk, Immune Exclusion)  \n",
                "‚úÖ Identified tumor, T-cell, and boundary regions  \n",
                "‚úÖ Validated resistance-velocity correlation  \n",
                "‚úÖ Performed ablation study  \n",
                "‚úÖ Stored all results in database  \n",
                "‚úÖ (Optional) Set up GNN training framework  \n",
                "\n",
                "**The Mechano-Velocity pipeline is complete!**\n",
                "\n",
                "For production use:\n",
                "1. Download trained models from Colab\n",
                "2. Run inference locally using the `mechano_velocity` package\n",
                "3. Query the database for historical comparisons"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}